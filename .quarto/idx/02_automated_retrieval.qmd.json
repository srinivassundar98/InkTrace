{"title":"2: Retrieval of raw data","markdown":{"yaml":{"title":"2: Retrieval of raw data"},"headingText":"Example command to download a dataset","containsRefs":false,"markdown":"\n\nOur project revolves around the classification of news articles based on authors and headlines. To gather the necessary data for this task, we utilized two primary sources accessed through the Python requests library and the Kaggle API:\n\nNews Category Dataset (via Kaggle API):\nThis dataset provides a vast collection of news articles categorized into different categories. It includes metadata such as headlines, authors, publication dates, and article content.\nAccessed through the Kaggle API, the News Category Dataset serves as a valuable resource for training and testing our classification models based on headline and author features.\nWe utilized the Kaggle api to write a script to get the news category dataset using an API call.\n\nAll the News Articles Dataset (via Kaggle API):\nComprising a diverse range of news articles from various sources, this dataset offers extensive coverage of news topics and authors.\nAcquired via the Kaggle API, the All the News Articles Dataset enriches our data collection efforts by providing additional samples for training and validation.\nBy leveraging the capabilities of the requests library and the Kaggle API, we obtained comprehensive datasets essential for our author and headline classification tasks. These datasets form the backbone of our project, enabling us to develop robust classification models and gain valuable insights into media narratives and authorship patterns.\n\nAll the News 2 News Articles Dataset\nThe dataset consists of a diverse selection of news articles from various sources and categories. For this dataset, we directly downloaded the sqlite and csv files from the website. The dataset was then stored locally for further preprocessing and analysis as part of our project.\n\nNYTimes Front Page Dataset\nFor the NYTimes Front Page Dataset, we utilized the provided Dropbox link to access the dataset containing data from the front page of The New York Times newspaper. After downloading the dataset, we parsed the CSV file to extract relevant metadata fields such as headlines, publication dates, and article content.\nThe dataset was then stored locally for preprocessing and integration into our analysis pipeline.\n\nBy programmatically retrieving and processing these datasets, we ensured a systematic approach to data acquisition, enabling us to conduct comprehensive analysis and classification tasks.\n\n```python\nimport requests\nimport zipfile\nimport os\nimport kaggle\n\ndef download_file_from_url(url, local_path):\n    \"\"\"\n    Download a file from a direct URL and save it locally.\n    \"\"\"\n    response = requests.get(url, stream=True)\n    response.raise_for_status()  # This will raise an exception if there is an error\n\n    with open(local_path, 'wb') as f:\n        for chunk in response.iter_content(chunk_size=8192):\n            f.write(chunk)\n\n    print(f\"File downloaded successfully and saved to {local_path}\")\n\n\ndef extract_zip(zip_path, extract_to):\n    \"\"\"\n    Extract a zip file to a specified directory.\n\n    Args:\n    zip_path (str): The path to the zip file.\n    extract_to (str): The directory to extract the files into.\n    \"\"\"\n    # Ensure the target directory exists\n    if not os.path.exists(extract_to):\n        os.makedirs(extract_to)\n\n    # Open the zip file\n    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n        # Extract all the contents into the directory\n        zip_ref.extractall(extract_to)\n        print(f\"All files have been extracted to {extract_to}\")\n\n\n# Replace 'username/dataset-name' with the actual path of the dataset on Kaggle\ndataset_identifier = 'rmisra/news-category-dataset'\n\n# Specify the path where you want to download the dataset\ndownload_path = 'news-category-dataset'\n\n# Download and unzip the dataset\nkaggle.api.dataset_download_files(dataset_identifier, path=download_path, unzip=True)\n\n\nurl1 = 'https://www.dropbox.com/scl/fi/pp8gbi3j7lxlunucs93xu/all-the-news.db?rlkey=iy65g92gd7bsaligula1disfn&e=1&dl=1'\nurl2 = 'https://www.dropbox.com/scl/fi/ri2muuv85ri98odyi9fzn/all-the-news-2-1.zip?rlkey=8qeq5kpg5btk3vq5nbx2aojxx&e=1&dl=1'\nurl3='https://www.dropbox.com/scl/fi/pm4c66u0exyj0ihaxr95e/nytimes%20front%20page.csv?rlkey=7mus7otnczy9w9q8wr3bo52ga&e=1&dl=1'\n# Local path where you want to save the file\nlocal_path1 = 'all-the-news.db'\nlocal_path2='all-the-news-2-1.zip'\nlocal_path3='nytimes_front_page.csv'\n\n\n\ndownload_file_from_url(url1, local_path1)\ndownload_file_from_url(url2, local_path2)\ndownload_file_from_url(url3, local_path3)\n# Path to your zip file\nzip_path = 'all-the-news-2-1.zip'\n\n# Directory to extract the contents\nextract_to = '.'\n\n# Call the function to extract the zip file\nextract_zip(zip_path, extract_to)\n\n```\n\nMore information can be found in the get_data.py file","srcMarkdownNoYaml":"\n\nOur project revolves around the classification of news articles based on authors and headlines. To gather the necessary data for this task, we utilized two primary sources accessed through the Python requests library and the Kaggle API:\n\nNews Category Dataset (via Kaggle API):\nThis dataset provides a vast collection of news articles categorized into different categories. It includes metadata such as headlines, authors, publication dates, and article content.\nAccessed through the Kaggle API, the News Category Dataset serves as a valuable resource for training and testing our classification models based on headline and author features.\nWe utilized the Kaggle api to write a script to get the news category dataset using an API call.\n\nAll the News Articles Dataset (via Kaggle API):\nComprising a diverse range of news articles from various sources, this dataset offers extensive coverage of news topics and authors.\nAcquired via the Kaggle API, the All the News Articles Dataset enriches our data collection efforts by providing additional samples for training and validation.\nBy leveraging the capabilities of the requests library and the Kaggle API, we obtained comprehensive datasets essential for our author and headline classification tasks. These datasets form the backbone of our project, enabling us to develop robust classification models and gain valuable insights into media narratives and authorship patterns.\n\nAll the News 2 News Articles Dataset\nThe dataset consists of a diverse selection of news articles from various sources and categories. For this dataset, we directly downloaded the sqlite and csv files from the website. The dataset was then stored locally for further preprocessing and analysis as part of our project.\n\nNYTimes Front Page Dataset\nFor the NYTimes Front Page Dataset, we utilized the provided Dropbox link to access the dataset containing data from the front page of The New York Times newspaper. After downloading the dataset, we parsed the CSV file to extract relevant metadata fields such as headlines, publication dates, and article content.\nThe dataset was then stored locally for preprocessing and integration into our analysis pipeline.\n\nBy programmatically retrieving and processing these datasets, we ensured a systematic approach to data acquisition, enabling us to conduct comprehensive analysis and classification tasks.\n\n```python\nimport requests\nimport zipfile\nimport os\nimport kaggle\n\ndef download_file_from_url(url, local_path):\n    \"\"\"\n    Download a file from a direct URL and save it locally.\n    \"\"\"\n    response = requests.get(url, stream=True)\n    response.raise_for_status()  # This will raise an exception if there is an error\n\n    with open(local_path, 'wb') as f:\n        for chunk in response.iter_content(chunk_size=8192):\n            f.write(chunk)\n\n    print(f\"File downloaded successfully and saved to {local_path}\")\n\n\ndef extract_zip(zip_path, extract_to):\n    \"\"\"\n    Extract a zip file to a specified directory.\n\n    Args:\n    zip_path (str): The path to the zip file.\n    extract_to (str): The directory to extract the files into.\n    \"\"\"\n    # Ensure the target directory exists\n    if not os.path.exists(extract_to):\n        os.makedirs(extract_to)\n\n    # Open the zip file\n    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n        # Extract all the contents into the directory\n        zip_ref.extractall(extract_to)\n        print(f\"All files have been extracted to {extract_to}\")\n\n\n# Example command to download a dataset\n# Replace 'username/dataset-name' with the actual path of the dataset on Kaggle\ndataset_identifier = 'rmisra/news-category-dataset'\n\n# Specify the path where you want to download the dataset\ndownload_path = 'news-category-dataset'\n\n# Download and unzip the dataset\nkaggle.api.dataset_download_files(dataset_identifier, path=download_path, unzip=True)\n\n\nurl1 = 'https://www.dropbox.com/scl/fi/pp8gbi3j7lxlunucs93xu/all-the-news.db?rlkey=iy65g92gd7bsaligula1disfn&e=1&dl=1'\nurl2 = 'https://www.dropbox.com/scl/fi/ri2muuv85ri98odyi9fzn/all-the-news-2-1.zip?rlkey=8qeq5kpg5btk3vq5nbx2aojxx&e=1&dl=1'\nurl3='https://www.dropbox.com/scl/fi/pm4c66u0exyj0ihaxr95e/nytimes%20front%20page.csv?rlkey=7mus7otnczy9w9q8wr3bo52ga&e=1&dl=1'\n# Local path where you want to save the file\nlocal_path1 = 'all-the-news.db'\nlocal_path2='all-the-news-2-1.zip'\nlocal_path3='nytimes_front_page.csv'\n\n\n\ndownload_file_from_url(url1, local_path1)\ndownload_file_from_url(url2, local_path2)\ndownload_file_from_url(url3, local_path3)\n# Path to your zip file\nzip_path = 'all-the-news-2-1.zip'\n\n# Directory to extract the contents\nextract_to = '.'\n\n# Call the function to extract the zip file\nextract_zip(zip_path, extract_to)\n\n```\n\nMore information can be found in the get_data.py file"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"02_automated_retrieval.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.551","theme":"cosmo","title":"2: Retrieval of raw data"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}