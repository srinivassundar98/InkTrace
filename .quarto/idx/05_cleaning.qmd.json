{"title":"5: Data cleaning","markdown":{"yaml":{"title":"5: Data cleaning"},"headingText":"Apply the function to the 'datetime' column","containsRefs":false,"markdown":"\n\n1. Handling Null Values:\nNull values in the dataset are addressed by dropping the corresponding rows. This ensures that the dataset remains consistent and usable for analysis without introducing bias or inaccuracies due to missing data.\n\n2. Selecting Specific Columns:\nOnly certain columns from the dataset are selected for further processing. These columns typically include essential information such as date, headline, article text, author, news outlet, and country of origin. By focusing on these specific columns, the analysis can concentrate on relevant aspects of the data.\n\n3. Enrichment Pipeline:\nAn enrichment pipeline is utilized to obtain additional metrics or features from the selected data. These metrics includes sentiment analysis, emotion analysis, text summarization, or any other relevant insights that enhance the understanding of the dataset.\n\n4. Renaming Column Headings:\nColumn headings are standardized and renamed to follow a consistent naming convention. For example, columns like \"source\" might be renamed to \"news_outlet\" to maintain uniformity and improve clarity across the dataset.\n\n5. Removing Duplicates:\nDuplicate entries in the dataset are identified by comparing values in the headline column. If multiple rows have identical headlines, they are considered duplicates and are subsequently removed from the dataset. This ensures data integrity and prevents redundancy in the analysis.\n\n6. Merging Datasets:\nFinally, all the individual datasets are merged into a single CSV file using the pandas library in Python. This consolidation combines the data from various sources into a unified dataset, providing a comprehensive and cohesive resource for further analysis and exploration.\n\n```python\nimport pandas as pd\nimport sqlite3\nimport json\njson_file_path=\"news-category-dataset\\\\News_Category_Dataset_v3.json\"\ndata = []\nwith open(json_file_path, 'r') as file:\n    for line in file:\n        json_object = json.loads(line)\n        data.append(json_object)\n\ndf_newscat = pd.DataFrame(data)\ndf_newscat_cleaned=df_newscat[[\"date\",\"authors\",\"headline\",\"short_description\"]]\n\ndf_all=pd.read_csv('all-the-news-2-1.csv')\ndf_ny_times=pd.read_csv('nytimes_front_page.csv')\n\ncon=sqlite3.connect('all-the-news.db')\ndf_allnews1=pd.read_sql('SELECT * FROM LONGFORM',con=con)\n\ndf_all_cleaned=df_all[[\"date\",\"title\",\"author\",\"article\"]]\ndf_all_cleaned.dropna(inplace=True)\ndef add_midnight(time_str):\n    if len(time_str) == 10:  # Just the date part (YYYY-MM-DD)\n        return time_str + ' 00:00:00'\n    else:\n        return time_str\n\ndf_all_cleaned['date'] = df_all_cleaned['date'].apply(add_midnight)\n\n# Convert the 'datetime' column to datetime format\ndf_all_cleaned['date'] = pd.to_datetime(df_all_cleaned['date'])\n\ndf_all_cleaned['date'] = df_all_cleaned['date'].dt.strftime('%Y-%m-%d')\n\ndf_ny_times=pd.read_csv('nytimes_front_page.csv')\n\ndf_ny_times_cleaned=df_ny_times[[\"date\",\"author\",\"title\",\"content\"]]\ndf_ny_times_cleaned.dropna(inplace=True)\n\ndf_allnews1_cleaned=df_allnews1[[\"date\",\"author\",\"title\",\"content\"]]\ndf_allnews1_cleaned.dropna(inplace=True)\n\ndf_all_cleaned.rename(columns={\n    'date': 'DATE',\n    'author': 'AUTHOR',\n    'title':'TITLE',\n    'article':'ARTICLE'\n    }, inplace=True)\n\ndf_allnews1_cleaned.rename(columns={\n    'date': 'DATE',\n    'author': 'AUTHOR',\n    'title':'TITLE',\n    'article':'ARTICLE'\n    }, inplace=True)\n\ndf_newscat_cleaned.rename(columns={\n    'date': 'DATE',\n    'authors': 'AUTHOR',\n    'headline':'TITLE',\n    'short_description':'ARTICLE'\n    }, inplace=True)\n\ndf_ny_times_cleaned.rename(columns={\n    'date': 'DATE',\n    'author': 'AUTHOR',\n    'title':'TITLE',\n    'content':'ARTICLE'\n    }, inplace=True)\n\n\ndataframes = [\n    df_all_cleaned,\n    df_allnews1_cleaned,\n    df_newscat_cleaned,\n    df_ny_times_cleaned\n]\n\n\n\n# Concatenate all DataFrames\ndf_combined = pd.concat(dataframes, ignore_index=True)\ndf_combined = df_combined.drop_duplicates()\nauthor_counts = df_combined['AUTHOR'].value_counts()\ntop_authors = author_counts.head(10)\ntop_authors_df = df_combined[df_combined['AUTHOR'].isin(top_authors.index)]\n\ndownsampled_df = top_authors_df.groupby('AUTHOR').head(5017)\n\n\ndownsampled_df.to_csv('cleaned_and_filtered.csv')\n```","srcMarkdownNoYaml":"\n\n1. Handling Null Values:\nNull values in the dataset are addressed by dropping the corresponding rows. This ensures that the dataset remains consistent and usable for analysis without introducing bias or inaccuracies due to missing data.\n\n2. Selecting Specific Columns:\nOnly certain columns from the dataset are selected for further processing. These columns typically include essential information such as date, headline, article text, author, news outlet, and country of origin. By focusing on these specific columns, the analysis can concentrate on relevant aspects of the data.\n\n3. Enrichment Pipeline:\nAn enrichment pipeline is utilized to obtain additional metrics or features from the selected data. These metrics includes sentiment analysis, emotion analysis, text summarization, or any other relevant insights that enhance the understanding of the dataset.\n\n4. Renaming Column Headings:\nColumn headings are standardized and renamed to follow a consistent naming convention. For example, columns like \"source\" might be renamed to \"news_outlet\" to maintain uniformity and improve clarity across the dataset.\n\n5. Removing Duplicates:\nDuplicate entries in the dataset are identified by comparing values in the headline column. If multiple rows have identical headlines, they are considered duplicates and are subsequently removed from the dataset. This ensures data integrity and prevents redundancy in the analysis.\n\n6. Merging Datasets:\nFinally, all the individual datasets are merged into a single CSV file using the pandas library in Python. This consolidation combines the data from various sources into a unified dataset, providing a comprehensive and cohesive resource for further analysis and exploration.\n\n```python\nimport pandas as pd\nimport sqlite3\nimport json\njson_file_path=\"news-category-dataset\\\\News_Category_Dataset_v3.json\"\ndata = []\nwith open(json_file_path, 'r') as file:\n    for line in file:\n        json_object = json.loads(line)\n        data.append(json_object)\n\ndf_newscat = pd.DataFrame(data)\ndf_newscat_cleaned=df_newscat[[\"date\",\"authors\",\"headline\",\"short_description\"]]\n\ndf_all=pd.read_csv('all-the-news-2-1.csv')\ndf_ny_times=pd.read_csv('nytimes_front_page.csv')\n\ncon=sqlite3.connect('all-the-news.db')\ndf_allnews1=pd.read_sql('SELECT * FROM LONGFORM',con=con)\n\ndf_all_cleaned=df_all[[\"date\",\"title\",\"author\",\"article\"]]\ndf_all_cleaned.dropna(inplace=True)\ndef add_midnight(time_str):\n    if len(time_str) == 10:  # Just the date part (YYYY-MM-DD)\n        return time_str + ' 00:00:00'\n    else:\n        return time_str\n\n# Apply the function to the 'datetime' column\ndf_all_cleaned['date'] = df_all_cleaned['date'].apply(add_midnight)\n\n# Convert the 'datetime' column to datetime format\ndf_all_cleaned['date'] = pd.to_datetime(df_all_cleaned['date'])\n\ndf_all_cleaned['date'] = df_all_cleaned['date'].dt.strftime('%Y-%m-%d')\n\ndf_ny_times=pd.read_csv('nytimes_front_page.csv')\n\ndf_ny_times_cleaned=df_ny_times[[\"date\",\"author\",\"title\",\"content\"]]\ndf_ny_times_cleaned.dropna(inplace=True)\n\ndf_allnews1_cleaned=df_allnews1[[\"date\",\"author\",\"title\",\"content\"]]\ndf_allnews1_cleaned.dropna(inplace=True)\n\ndf_all_cleaned.rename(columns={\n    'date': 'DATE',\n    'author': 'AUTHOR',\n    'title':'TITLE',\n    'article':'ARTICLE'\n    }, inplace=True)\n\ndf_allnews1_cleaned.rename(columns={\n    'date': 'DATE',\n    'author': 'AUTHOR',\n    'title':'TITLE',\n    'article':'ARTICLE'\n    }, inplace=True)\n\ndf_newscat_cleaned.rename(columns={\n    'date': 'DATE',\n    'authors': 'AUTHOR',\n    'headline':'TITLE',\n    'short_description':'ARTICLE'\n    }, inplace=True)\n\ndf_ny_times_cleaned.rename(columns={\n    'date': 'DATE',\n    'author': 'AUTHOR',\n    'title':'TITLE',\n    'content':'ARTICLE'\n    }, inplace=True)\n\n\ndataframes = [\n    df_all_cleaned,\n    df_allnews1_cleaned,\n    df_newscat_cleaned,\n    df_ny_times_cleaned\n]\n\n\n\n# Concatenate all DataFrames\ndf_combined = pd.concat(dataframes, ignore_index=True)\ndf_combined = df_combined.drop_duplicates()\nauthor_counts = df_combined['AUTHOR'].value_counts()\ntop_authors = author_counts.head(10)\ntop_authors_df = df_combined[df_combined['AUTHOR'].isin(top_authors.index)]\n\ndownsampled_df = top_authors_df.groupby('AUTHOR').head(5017)\n\n\ndownsampled_df.to_csv('cleaned_and_filtered.csv')\n```"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"05_cleaning.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.40","theme":"cosmo","title":"5: Data cleaning"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}